{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing multinomial Naive Bayes classifier on ‘20 Newsgroups Dataset’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2022.1.18)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\RAZORBLADE\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp39-cp39-win_amd64.whl (7.2 MB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.20.2)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
      "Installing collected packages: threadpoolctl, scikit-learn, sklearn\n",
      "    Running setup.py install for sklearn: started\n",
      "    Running setup.py install for sklearn: finished with status 'done'\n",
      "Successfully installed scikit-learn-1.0.2 sklearn-0.0 threadpoolctl-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\RAZORBLADE\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import os\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypath = r\"C:\\Users\\RAZORBLADE\\Desktop\\20news-19997\\20_newsgroups\"\n",
    "files = [f for f in os.listdir(mypath)]\n",
    "files.sort()\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words\n",
    "\n",
    "Stop words are words that show up a lot in every document (e.g. prepositions and pronouns). Since stop words are of no use for us we will not consider them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RAZORBLADE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RAZORBLADE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "punctuations=list(punctuation)\n",
    "stopWords=stopwords.words('english')\n",
    "stopWords+=punctuations \n",
    "len(stopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Vocabulary/Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab_dict will be a dictionary of the form {word: frequency} over all documents\n",
    "vocab_dict = {}\n",
    "for file in files:\n",
    "    for doc in os.listdir(os.path.join(mypath, file)):\n",
    "        with open(os.path.join(mypath, file,doc), 'r') as f:\n",
    "            text = f.read()\n",
    "            text = text.lower()\n",
    "            for token in text.split():\n",
    "                if token in vocab_dict:\n",
    "                    vocab_dict[token] += 1\n",
    "                elif len(token) >=5 and token not in stopWords:\n",
    "                    vocab_dict[token] = 1\n",
    "\n",
    "len(vocab_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Feature List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dictionary based on frequency of each 'possible' vocabulary word\n",
    "sorted_vocab=sorted(vocab_dict.items(),key=operator.itemgetter(1),reverse=True)\n",
    "# Choosing top 2000 vocab words as features\n",
    "feature_list=[]\n",
    "for key in sorted_vocab:\n",
    "    feature_list.append(key[0])\n",
    "feature_list=feature_list[0:2000] # K = 2000 (number of words in vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(folder_location,file_location):\n",
    "    '''\n",
    "    :param file_location : location of folder to distinguish between training and test folder\n",
    "    :return : Y as an array conatining all corresponding newsgroups and X as dataframe values where each column represents a particular word\n",
    "                and the value is the count of the word in a given document/article.\n",
    "    '''\n",
    "\n",
    "    my_path = os.path.join(r\"C:\\Users\\RAZORBLADE\\Desktop\",folder_location,file_location)\n",
    "    df = pd.DataFrame(columns = feature_list)\n",
    "    Y=[]\n",
    "    for file in files:\n",
    "        for doc in os.listdir(os.path.join(my_path, file)):\n",
    "            Y.append(file)\n",
    "            # Add a new row for every file\n",
    "            df.loc[len(df)] = np.zeros(len(feature_list))\n",
    "            with open(os.path.join(my_path, file,doc), 'r') as f:\n",
    "                text = f.read()\n",
    "                text = text.lower()\n",
    "                for token in text.split():\n",
    "                    if token.lower() in feature_list:\n",
    "                        df[token.lower()][len(df)-1] += 1 \n",
    "        \n",
    "    # add Y as a column to dataframe\n",
    "    df['newsgroups']=Y\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Test Data and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(\"20news-19997\",\"20_newsgroups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject:</th>\n",
       "      <th>from:</th>\n",
       "      <th>date:</th>\n",
       "      <th>newsgroups:</th>\n",
       "      <th>message-id:</th>\n",
       "      <th>lines:</th>\n",
       "      <th>path:</th>\n",
       "      <th>organization:</th>\n",
       "      <th>would</th>\n",
       "      <th>writes:</th>\n",
       "      <th>...</th>\n",
       "      <th>(including</th>\n",
       "      <th>resulting</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>planetary</th>\n",
       "      <th>pitching</th>\n",
       "      <th>previously</th>\n",
       "      <th>replies</th>\n",
       "      <th>helps</th>\n",
       "      <th>cities</th>\n",
       "      <th>newsgroups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject:  from:  date:  newsgroups:  message-id:  lines:  path:  \\\n",
       "0       1.0    1.0    1.0          1.0          1.0     1.0    1.0   \n",
       "1       1.0    1.0    1.0          1.0          1.0     1.0    1.0   \n",
       "2       1.0    1.0    1.0          1.0          1.0     1.0    1.0   \n",
       "3       1.0    1.0    1.0          1.0          1.0     1.0    1.0   \n",
       "4       1.0    1.0    1.0          1.0          1.0     1.0    1.0   \n",
       "\n",
       "   organization:  would  writes:  ...  (including  resulting  yesterday  \\\n",
       "0            1.0    0.0      0.0  ...         0.0        0.0        0.0   \n",
       "1            1.0    7.0      0.0  ...         0.0        0.0        0.0   \n",
       "2            1.0    4.0      1.0  ...         0.0        0.0        0.0   \n",
       "3            1.0    0.0      1.0  ...         0.0        0.0        0.0   \n",
       "4            1.0    0.0      1.0  ...         0.0        0.0        0.0   \n",
       "\n",
       "   planetary  pitching  previously  replies  helps  cities   newsgroups  \n",
       "0        0.0       0.0         0.0      0.0    0.0     0.0  alt.atheism  \n",
       "1        0.0       0.0         1.0      0.0    0.0     0.0  alt.atheism  \n",
       "2        0.0       0.0         0.0      0.0    0.0     0.0  alt.atheism  \n",
       "3        0.0       0.0         0.0      0.0    0.0     0.0  alt.atheism  \n",
       "4        0.0       0.0         0.0      0.0    0.0     0.0  alt.atheism  \n",
       "\n",
       "[5 rows x 2001 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['newsgroups'],axis=1).values\n",
    "#remove last column of X\n",
    "\n",
    "Y = df['newsgroups'].values\n",
    "#check if there is a NaN value in df\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,random_state=0,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the inbuilt Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.829"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf=MultinomialNB()\n",
    "clf.fit(x_train,y_train)\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism 0.05114356204574248\n",
      "comp.graphics 0.04980996199239848\n",
      "comp.os.ms-windows.misc 0.05007668200306728\n",
      "comp.sys.ibm.pc.hardware 0.05067680202707208\n",
      "comp.sys.mac.hardware 0.050943522037740885\n",
      "comp.windows.x 0.05067680202707208\n",
      "misc.forsale 0.04927652197106088\n",
      "rec.autos 0.04874308194972328\n",
      "rec.motorcycles 0.047742881909715276\n",
      "rec.sport.baseball 0.05014336200573448\n",
      "rec.sport.hockey 0.05127692205107688\n",
      "sci.crypt 0.05114356204574248\n",
      "sci.electronics 0.05041008201640328\n",
      "sci.med 0.04960992198439688\n",
      "sci.space 0.05027672201106888\n",
      "soc.religion.christian 0.04967660198706408\n",
      "talk.politics.guns 0.05007668200306728\n",
      "talk.politics.mideast 0.047942921917716874\n",
      "talk.politics.misc 0.04940988197639528\n",
      "talk.religion.misc 0.050943522037740885\n"
     ]
    }
   ],
   "source": [
    "# calculate posteriors for each type of file\n",
    "posteriors ={}\n",
    "for file in files:\n",
    "    posteriors[file] = len(y_train[y_train==file]) / len(y_train)\n",
    "    print(file,posteriors[file])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject:</th>\n",
       "      <th>from:</th>\n",
       "      <th>date:</th>\n",
       "      <th>newsgroups:</th>\n",
       "      <th>message-id:</th>\n",
       "      <th>lines:</th>\n",
       "      <th>path:</th>\n",
       "      <th>organization:</th>\n",
       "      <th>would</th>\n",
       "      <th>writes:</th>\n",
       "      <th>...</th>\n",
       "      <th>conditions</th>\n",
       "      <th>(including</th>\n",
       "      <th>resulting</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>planetary</th>\n",
       "      <th>pitching</th>\n",
       "      <th>previously</th>\n",
       "      <th>replies</th>\n",
       "      <th>helps</th>\n",
       "      <th>cities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject:  from:  date:  newsgroups:  message-id:  lines:  path:  \\\n",
       "0       0.0    0.0    0.0          0.0          0.0     0.0    0.0   \n",
       "1       0.0    0.0    0.0          0.0          0.0     0.0    0.0   \n",
       "2       0.0    0.0    0.0          0.0          0.0     0.0    0.0   \n",
       "3       0.0    0.0    0.0          0.0          0.0     0.0    0.0   \n",
       "4       0.0    0.0    0.0          0.0          0.0     0.0    0.0   \n",
       "\n",
       "   organization:  would  writes:  ...  conditions  (including  resulting  \\\n",
       "0            0.0    0.0      0.0  ...         0.0         0.0        0.0   \n",
       "1            0.0    0.0      0.0  ...         0.0         0.0        0.0   \n",
       "2            0.0    0.0      0.0  ...         0.0         0.0        0.0   \n",
       "3            0.0    0.0      0.0  ...         0.0         0.0        0.0   \n",
       "4            0.0    0.0      0.0  ...         0.0         0.0        0.0   \n",
       "\n",
       "   yesterday  planetary  pitching  previously  replies  helps  cities  \n",
       "0        0.0        0.0       0.0         0.0      0.0    0.0     0.0  \n",
       "1        0.0        0.0       0.0         0.0      0.0    0.0     0.0  \n",
       "2        0.0        0.0       0.0         0.0      0.0    0.0     0.0  \n",
       "3        0.0        0.0       0.0         0.0      0.0    0.0     0.0  \n",
       "4        0.0        0.0       0.0         0.0      0.0    0.0     0.0  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate class conditional probabilities p(x|y) where x is a word and y is a newsgroup for each word in the vocabulary as a dataframe\n",
    "conditional_probabilities = pd.DataFrame(columns=feature_list)\n",
    "i=0;\n",
    "for file in files:\n",
    "    # add a new row for each file\n",
    "    conditional_probabilities.loc[len(conditional_probabilities)] = np.zeros(len(feature_list))\n",
    "    # use df calculated above to calculate conditional probabilities\n",
    "    for word in feature_list:\n",
    "        conditional_probabilities[word][i] = (df[word][df['newsgroups']==file].sum() + 1) / (len(df[df['newsgroups']==file]) + len(feature_list))\n",
    "        i+=1\n",
    "conditional_probabilities.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    # calculate the probability of each word in the text belonging to each newsgroup\n",
    "    probabilities = {}\n",
    "    for file in files:\n",
    "        probabilities[file] = np.log(posteriors[file])\n",
    "        for word in text:\n",
    "            if word in feature_list:\n",
    "                probabilities[file] += np.log(conditional_probabilities[file][word])*vocab_dict[word]\n",
    "    # return the newsgroup with the highest probability\n",
    "    return max(probabilities, key=probabilities.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data(x_test):\n",
    "    predictions = []\n",
    "    for i in range(len(x_test)):\n",
    "        predictions.append(predict(x_test[i]))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "y_pred=predict_data(x_test)\n",
    "print(confusion_matrix(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74fc0cb1932bf4b202d61f4ecf9d651fa79ff967900f756d776817a87c2d0209"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
