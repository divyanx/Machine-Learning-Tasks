{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing multinomial Naive Bayes classifier on ‘20 Newsgroups Dataset’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: click in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2022.1.18)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\RAZORBLADE\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.20.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\RAZORBLADE\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import os\n",
    "import nltk\n",
    "from string import punctuation\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypath = r\"C:\\Users\\RAZORBLADE\\Desktop\\20news-19997\\20_newsgroups\"\n",
    "folders = [f for f in os.listdir(mypath)]\n",
    "folders.sort()\n",
    "folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words\n",
    "\n",
    "Stop words are words that show up a lot in every document (e.g. prepositions and pronouns). Since stop words are of no use for us we will not consider them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RAZORBLADE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RAZORBLADE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "punctuations=list(punctuation)\n",
    "stopWords=stopwords.words('english')\n",
    "stopWords+=punctuations \n",
    "stopWords= set(stopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Vocabulary/Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90926"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab_dict will be a dictionary of the form {word: frequency} over all documents\n",
    "\n",
    "data = {}\n",
    "vocab_dict = {}\n",
    "for folder in folders:\n",
    "    data[folder] = []\n",
    "    for doc in os.listdir(os.path.join(mypath, folder)):\n",
    "        with open(os.path.join(mypath, folder,doc), 'r') as f:\n",
    "            text = f.read()\n",
    "            text = text.lower()\n",
    "            # remove any word that has a non alphabetical character\n",
    "            text = re.sub(r'[^a-z]', ' ', text)\n",
    "            temp=text.split()\n",
    "            data[folder].append(temp)\n",
    "            for token in temp:\n",
    "                if token in vocab_dict:\n",
    "                    vocab_dict[token] += 1\n",
    "                elif len(token) >=5 and token not in stopWords:\n",
    "                    vocab_dict[token] = 1\n",
    "                    \n",
    "            \n",
    "\n",
    "len(vocab_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5430"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[folders[0]][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Feature List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'access',\n",
       " 'actually',\n",
       " 'agate',\n",
       " 'always',\n",
       " 'american',\n",
       " 'andrew',\n",
       " 'another',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'apple',\n",
       " 'around',\n",
       " 'article',\n",
       " 'atheism',\n",
       " 'athos',\n",
       " 'autos',\n",
       " 'available',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'believe',\n",
       " 'berkeley',\n",
       " 'better',\n",
       " 'called',\n",
       " 'cantaloupe',\n",
       " 'center',\n",
       " 'change',\n",
       " 'children',\n",
       " 'christian',\n",
       " 'clipper',\n",
       " 'colorado',\n",
       " 'columbia',\n",
       " 'computer',\n",
       " 'control',\n",
       " 'could',\n",
       " 'course',\n",
       " 'crabapple',\n",
       " 'crypt',\n",
       " 'culture',\n",
       " 'darwin',\n",
       " 'david',\n",
       " 'different',\n",
       " 'distribution',\n",
       " 'drive',\n",
       " 'either',\n",
       " 'electronics',\n",
       " 'email',\n",
       " 'enough',\n",
       " 'europa',\n",
       " 'every',\n",
       " 'evidence',\n",
       " 'example',\n",
       " 'files',\n",
       " 'first',\n",
       " 'following',\n",
       " 'followup',\n",
       " 'forsale',\n",
       " 'found',\n",
       " 'games',\n",
       " 'gatech',\n",
       " 'general',\n",
       " 'geneva',\n",
       " 'getting',\n",
       " 'given',\n",
       " 'going',\n",
       " 'government',\n",
       " 'graphics',\n",
       " 'great',\n",
       " 'group',\n",
       " 'gtefsd',\n",
       " 'hardware',\n",
       " 'harvard',\n",
       " 'heard',\n",
       " 'history',\n",
       " 'hockey',\n",
       " 'however',\n",
       " 'howland',\n",
       " 'human',\n",
       " 'image',\n",
       " 'information',\n",
       " 'internet',\n",
       " 'israel',\n",
       " 'jesus',\n",
       " 'jewish',\n",
       " 'keywords',\n",
       " 'least',\n",
       " 'lines',\n",
       " 'little',\n",
       " 'local',\n",
       " 'looking',\n",
       " 'magnesium',\n",
       " 'makes',\n",
       " 'maybe',\n",
       " 'means',\n",
       " 'message',\n",
       " 'michael',\n",
       " 'mideast',\n",
       " 'might',\n",
       " 'national',\n",
       " 'netcom',\n",
       " 'network',\n",
       " 'never',\n",
       " 'newsgroups',\n",
       " 'nothing',\n",
       " 'number',\n",
       " 'opinions',\n",
       " 'order',\n",
       " 'organization',\n",
       " 'others',\n",
       " 'people',\n",
       " 'person',\n",
       " 'phone',\n",
       " 'place',\n",
       " 'please',\n",
       " 'point',\n",
       " 'politics',\n",
       " 'possible',\n",
       " 'posting',\n",
       " 'power',\n",
       " 'president',\n",
       " 'price',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'program',\n",
       " 'public',\n",
       " 'purdue',\n",
       " 'question',\n",
       " 'questions',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'references',\n",
       " 'religion',\n",
       " 'remember',\n",
       " 'reply',\n",
       " 'research',\n",
       " 'reston',\n",
       " 'right',\n",
       " 'rights',\n",
       " 'rochester',\n",
       " 'rutgers',\n",
       " 'saying',\n",
       " 'science',\n",
       " 'second',\n",
       " 'security',\n",
       " 'seems',\n",
       " 'sender',\n",
       " 'server',\n",
       " 'service',\n",
       " 'several',\n",
       " 'since',\n",
       " 'software',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'source',\n",
       " 'space',\n",
       " 'sport',\n",
       " 'standard',\n",
       " 'stanford',\n",
       " 'start',\n",
       " 'state',\n",
       " 'steve',\n",
       " 'still',\n",
       " 'subject',\n",
       " 'support',\n",
       " 'system',\n",
       " 'systems',\n",
       " 'technology',\n",
       " 'thanks',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'three',\n",
       " 'times',\n",
       " 'today',\n",
       " 'toronto',\n",
       " 'trying',\n",
       " 'turkish',\n",
       " 'university',\n",
       " 'usenet',\n",
       " 'using',\n",
       " 'utexas',\n",
       " 'uunet',\n",
       " 'version',\n",
       " 'virginia',\n",
       " 'wanted',\n",
       " 'washington',\n",
       " 'whether',\n",
       " 'window',\n",
       " 'windows',\n",
       " 'without',\n",
       " 'world',\n",
       " 'would',\n",
       " 'writes',\n",
       " 'wrong',\n",
       " 'wrote',\n",
       " 'years',\n",
       " 'zaphod'}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the dictionary based on frequency of each 'possible' vocabulary word\n",
    "sorted_vocab=sorted(vocab_dict.items(),key=operator.itemgetter(1),reverse=True)\n",
    "# Choosing top 2000 vocab words as features\n",
    "feature_list=[]\n",
    "for key in sorted_vocab:\n",
    "    feature_list.append(key[0])\n",
    "feature_list=feature_list[0:200] # K = 200 (number of words in vocab)\n",
    "feature_list = set(feature_list)\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    '''\n",
    "    return : a dataframe of columns as features and rows as documents\n",
    "    '''\n",
    "    df = pd.DataFrame(columns = feature_list)\n",
    "    Y=[]\n",
    "    for folder in folders:\n",
    "        for doc in data[folder]:\n",
    "            Y.append(folder)\n",
    "            # Add a new row for every file\n",
    "            df.loc[len(df)] = np.zeros(len(feature_list))\n",
    "            for txt in doc:\n",
    "                for word in txt.split():\n",
    "                    if word in feature_list:\n",
    "                        df.loc[len(df)-1,word] += 1\n",
    "        \n",
    "    # add Y as a column to dataframe\n",
    "    df['Y']=Y\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Test Data and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maybe</th>\n",
       "      <th>rochester</th>\n",
       "      <th>jesus</th>\n",
       "      <th>looking</th>\n",
       "      <th>support</th>\n",
       "      <th>heard</th>\n",
       "      <th>wanted</th>\n",
       "      <th>network</th>\n",
       "      <th>apple</th>\n",
       "      <th>atheism</th>\n",
       "      <th>...</th>\n",
       "      <th>remember</th>\n",
       "      <th>source</th>\n",
       "      <th>getting</th>\n",
       "      <th>given</th>\n",
       "      <th>research</th>\n",
       "      <th>history</th>\n",
       "      <th>saying</th>\n",
       "      <th>electronics</th>\n",
       "      <th>culture</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   maybe  rochester  jesus  looking  support  heard  wanted  network  apple  \\\n",
       "0    0.0        0.0    0.0      0.0      0.0    0.0     0.0      0.0    0.0   \n",
       "1    1.0        0.0    4.0      1.0      1.0    0.0     0.0      0.0    0.0   \n",
       "2    0.0        0.0    1.0      0.0      0.0    0.0     0.0      0.0    0.0   \n",
       "3    0.0        0.0    1.0      0.0      1.0    1.0     0.0      0.0    0.0   \n",
       "4    0.0        0.0    0.0      0.0      0.0    0.0     0.0      0.0    0.0   \n",
       "\n",
       "   atheism  ...  remember  source  getting  given  research  history  saying  \\\n",
       "0     18.0  ...       0.0     0.0      0.0    0.0       0.0      6.0     1.0   \n",
       "1     57.0  ...       1.0     0.0      0.0    0.0       0.0      1.0     2.0   \n",
       "2      1.0  ...       0.0     2.0      0.0    0.0       0.0      0.0     0.0   \n",
       "3      2.0  ...       0.0     0.0      0.0    0.0       0.0      0.0     1.0   \n",
       "4      2.0  ...       0.0     0.0      0.0    0.0       2.0      0.0     0.0   \n",
       "\n",
       "   electronics  culture            Y  \n",
       "0          0.0      0.0  alt.atheism  \n",
       "1          0.0      0.0  alt.atheism  \n",
       "2          0.0      0.0  alt.atheism  \n",
       "3          0.0      0.0  alt.atheism  \n",
       "4          0.0      0.0  alt.atheism  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['Y'],axis=1).values\n",
    "#remove last column of X\n",
    "\n",
    "Y = df['Y'].values\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\RAZORBLADE\\Desktop\\Sem-VI\\CS331 - ML\\Machine-Learning-Tasks\\Machine-Learning-Tasks\\Assignment-02\\Q3\\QIII_2.ipynb Cell 19'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-02/Q3/QIII_2.ipynb#ch0000057?line=0'>1</a>\u001b[0m \u001b[39m# divide each row of df by sum of all values in that row except the last column\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-02/Q3/QIII_2.ipynb#ch0000057?line=1'>2</a>\u001b[0m df[df\u001b[39m.\u001b[39mcolumns[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]] \u001b[39m=\u001b[39m df[df\u001b[39m.\u001b[39mcolumns[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]]\u001b[39m/\u001b[39mdf[df\u001b[39m.\u001b[39mcolumns[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]]\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3597\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/frame.py?line=3594'>3595</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_frame(key, value)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/frame.py?line=3595'>3596</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, (Series, np\u001b[39m.\u001b[39mndarray, \u001b[39mlist\u001b[39m, Index)):\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/frame.py?line=3596'>3597</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_array(key, value)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/frame.py?line=3597'>3598</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/frame.py?line=3598'>3599</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3634\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/frame.py?line=3631'>3632</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/frame.py?line=3632'>3633</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/frame.py?line=3633'>3634</a>\u001b[0m         check_key_length(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns, key, value)\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/frame.py?line=3634'>3635</a>\u001b[0m         \u001b[39mfor\u001b[39;00m k1, k2 \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(key, value\u001b[39m.\u001b[39mcolumns):\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/frame.py?line=3635'>3636</a>\u001b[0m             \u001b[39mself\u001b[39m[k1] \u001b[39m=\u001b[39m value[k2]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexers.py:428\u001b[0m, in \u001b[0;36mcheck_key_length\u001b[1;34m(columns, key, value)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexers.py?line=425'>426</a>\u001b[0m \u001b[39mif\u001b[39;00m columns\u001b[39m.\u001b[39mis_unique:\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexers.py?line=426'>427</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(value\u001b[39m.\u001b[39mcolumns) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(key):\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexers.py?line=427'>428</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mColumns must be same length as key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexers.py?line=428'>429</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexers.py?line=429'>430</a>\u001b[0m     \u001b[39m# Missing keys in columns are represented as -1\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/indexers.py?line=430'>431</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(columns\u001b[39m.\u001b[39mget_indexer_non_unique(key)[\u001b[39m0\u001b[39m]) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(value\u001b[39m.\u001b[39mcolumns):\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "# divide each row of df by sum of all values in that row except the last column\n",
    "df[df.columns[:-1]] = df[df.columns[:-1]]/df[df.columns[:-1]].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,random_state=0,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'talk.politics.misc': 741,\n",
       "         'talk.religion.misc': 764,\n",
       "         'sci.electronics': 756,\n",
       "         'misc.forsale': 739,\n",
       "         'rec.motorcycles': 716,\n",
       "         'comp.sys.mac.hardware': 764,\n",
       "         'rec.sport.hockey': 769,\n",
       "         'talk.politics.mideast': 719,\n",
       "         'soc.religion.christian': 745,\n",
       "         'sci.med': 744,\n",
       "         'comp.os.ms-windows.misc': 751,\n",
       "         'talk.politics.guns': 751,\n",
       "         'alt.atheism': 767,\n",
       "         'comp.graphics': 747,\n",
       "         'comp.sys.ibm.pc.hardware': 760,\n",
       "         'rec.sport.baseball': 752,\n",
       "         'sci.crypt': 767,\n",
       "         'rec.autos': 731,\n",
       "         'sci.space': 754,\n",
       "         'comp.windows.x': 760})"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count each distinct element in the y_train\n",
    "from collections import Counter\n",
    "Counter(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the inbuilt Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.767"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf=MultinomialNB()\n",
    "clf.fit(x_train,y_train)\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism 0.05114356204574248\n",
      "comp.graphics 0.04980996199239848\n",
      "comp.os.ms-windows.misc 0.05007668200306728\n",
      "comp.sys.ibm.pc.hardware 0.05067680202707208\n",
      "comp.sys.mac.hardware 0.050943522037740885\n",
      "comp.windows.x 0.05067680202707208\n",
      "misc.forsale 0.04927652197106088\n",
      "rec.autos 0.04874308194972328\n",
      "rec.motorcycles 0.047742881909715276\n",
      "rec.sport.baseball 0.05014336200573448\n",
      "rec.sport.hockey 0.05127692205107688\n",
      "sci.crypt 0.05114356204574248\n",
      "sci.electronics 0.05041008201640328\n",
      "sci.med 0.04960992198439688\n",
      "sci.space 0.05027672201106888\n",
      "soc.religion.christian 0.04967660198706408\n",
      "talk.politics.guns 0.05007668200306728\n",
      "talk.politics.mideast 0.047942921917716874\n",
      "talk.politics.misc 0.04940988197639528\n",
      "talk.religion.misc 0.050943522037740885\n"
     ]
    }
   ],
   "source": [
    "# calculate posteriors for each type of folder\n",
    "posteriors ={}\n",
    "for folder in folders:\n",
    "    posteriors[folder] = len(y_train[y_train==folder]) / len(y_train)\n",
    "    print(folder,posteriors[folder])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22583333333333333"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word= 'example'\n",
    "folder=folders[0]\n",
    "(df[word][df['Y']==folder].sum() + 1) / (len(df[df['Y']==folder]) + len(feature_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maybe</th>\n",
       "      <th>rochester</th>\n",
       "      <th>jesus</th>\n",
       "      <th>looking</th>\n",
       "      <th>support</th>\n",
       "      <th>heard</th>\n",
       "      <th>wanted</th>\n",
       "      <th>network</th>\n",
       "      <th>apple</th>\n",
       "      <th>atheism</th>\n",
       "      <th>...</th>\n",
       "      <th>however</th>\n",
       "      <th>remember</th>\n",
       "      <th>source</th>\n",
       "      <th>getting</th>\n",
       "      <th>given</th>\n",
       "      <th>research</th>\n",
       "      <th>history</th>\n",
       "      <th>saying</th>\n",
       "      <th>electronics</th>\n",
       "      <th>culture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080833</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.301667</td>\n",
       "      <td>0.039167</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>0.031667</td>\n",
       "      <td>0.040833</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170833</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.128333</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>0.184167</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.036667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.168333</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081667</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.147500</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.060833</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.010833</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.194167</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.099167</td>\n",
       "      <td>0.048333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.134167</td>\n",
       "      <td>0.025833</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081667</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.015833</td>\n",
       "      <td>0.060833</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050833</td>\n",
       "      <td>0.174167</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.075833</td>\n",
       "      <td>0.129167</td>\n",
       "      <td>0.068333</td>\n",
       "      <td>0.065833</td>\n",
       "      <td>0.098333</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>0.025833</td>\n",
       "      <td>0.078333</td>\n",
       "      <td>0.019167</td>\n",
       "      <td>0.059167</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.000833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035833</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.065833</td>\n",
       "      <td>0.089167</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0.081667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.709167</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.000833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      maybe  rochester     jesus   looking   support     heard    wanted  \\\n",
       "0  0.080833   0.017500  0.301667  0.039167  0.105000  0.056667  0.031667   \n",
       "1  0.037500   0.175000  0.000833  0.187500  0.168333  0.060000  0.051667   \n",
       "2  0.058333   0.194167  0.000833  0.092500  0.099167  0.048333  0.041667   \n",
       "3  0.050833   0.174167  0.001667  0.075833  0.129167  0.068333  0.065833   \n",
       "4  0.035833   0.200000  0.000833  0.065833  0.089167  0.086667  0.081667   \n",
       "\n",
       "    network     apple   atheism  ...   however  remember    source   getting  \\\n",
       "0  0.040833  0.262500  1.520000  ...  0.170833  0.060000  0.042500  0.050000   \n",
       "1  0.104167  0.055000  0.000833  ...  0.081667  0.023333  0.147500  0.045000   \n",
       "2  0.134167  0.025833  0.001667  ...  0.081667  0.051667  0.029167  0.052500   \n",
       "3  0.098333  0.020000  0.000833  ...  0.085000  0.028333  0.025833  0.078333   \n",
       "4  0.116667  0.709167  0.000833  ...  0.057500  0.033333  0.029167  0.077500   \n",
       "\n",
       "      given  research   history    saying  electronics   culture  \n",
       "0  0.128333  0.037500  0.108333  0.184167     0.001667  0.036667  \n",
       "1  0.060833  0.173333  0.004167  0.027500     0.010833  0.005000  \n",
       "2  0.015833  0.060833  0.002500  0.017500     0.010000  0.005000  \n",
       "3  0.019167  0.059167  0.001667  0.011667     0.020833  0.000833  \n",
       "4  0.028333  0.042500  0.000833  0.020833     0.020833  0.000833  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate class conditional probabilities p(x|y) where x is a word and y is a newsgroup for each word in the vocabulary as a dataframe\n",
    "conditional_probabilities = pd.DataFrame(columns=feature_list)\n",
    "i=0;\n",
    "for folder in folders:\n",
    "    # add a new row for each folder\n",
    "    conditional_probabilities.loc[len(conditional_probabilities)] = np.zeros(len(feature_list))\n",
    "    # use df calculated above to calculate conditional probabilities\n",
    "    for word in feature_list:\n",
    "        #print(word)\n",
    "        conditional_probabilities[word][i] = (df[word][df['Y']==folder].sum() + 1) / (len(df[df['Y']==folder]) + len(feature_list))\n",
    "    i+=1\n",
    "conditional_probabilities.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maybe          1.0\n",
       "rochester      1.0\n",
       "jesus          1.0\n",
       "looking        1.0\n",
       "support        1.0\n",
       "              ... \n",
       "research       1.0\n",
       "history        1.0\n",
       "saying         1.0\n",
       "electronics    1.0\n",
       "culture        1.0\n",
       "Length: 200, dtype: float64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize each columns of conditional_probabilities\n",
    "conditional_probabilities = conditional_probabilities.div(conditional_probabilities.sum(axis=0), axis=1)\n",
    "# get the sum of each column\n",
    "conditional_probabilities.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a={'a':1,'b':2,'c':3}\n",
    "max(a,key=a.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    # calculate the probability of each word in the text belonging to each newsgroup\n",
    "    probabilities = {}\n",
    "    i=0\n",
    "    for f_in in range(len(folders)):\n",
    "        probabilities[folders[f_in]] = np.log(posteriors[folders[f_in]])\n",
    "        for i in range(len(text)):\n",
    "            probabilities[folders[f_in]] += np.log(conditional_probabilities.values[f_in][i])*text[i]\n",
    "    # return the newsgroup with the highest probability\n",
    "    # print(probabilities)\n",
    "    return max(probabilities, key=probabilities.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data(x_test):\n",
    "    predictions = []\n",
    "    for i in range(len(x_test)):\n",
    "        print(':',end=\" \")\n",
    "        predictions.append(predict(x_test[i]))\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "y_pred=predict_data(x_test)\n",
    "# print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6192"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred==y_test)/len(y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74fc0cb1932bf4b202d61f4ecf9d651fa79ff967900f756d776817a87c2d0209"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
