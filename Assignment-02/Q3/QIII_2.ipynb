{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing multinomial Naive Bayes classifier on ‘20 Newsgroups Dataset’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2022.1.18)\n",
      "Requirement already satisfied: tqdm in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\RAZORBLADE\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.20.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\razorblade\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\RAZORBLADE\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import os\n",
    "import nltk\n",
    "from string import punctuation\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypath = r\"C:\\Users\\RAZORBLADE\\Desktop\\20news-19997\\20_newsgroups\"\n",
    "folders = [f for f in os.listdir(mypath)]\n",
    "folders.sort()\n",
    "folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words\n",
    "\n",
    "Stop words are words that show up a lot in every document (e.g. prepositions and pronouns). Since stop words are of no use for us we will not consider them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RAZORBLADE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RAZORBLADE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "punctuations=list(punctuation)\n",
    "stopWords=stopwords.words('english')\n",
    "stopWords+=punctuations \n",
    "stopWords= set(stopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Vocabulary/Feature Set\n",
    "\n",
    "Vocabulary will contain words that will act as features for our model , we will take some amount of words from all documents sorted by frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90926"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab_dict will be a dictionary of the form {word: frequency} over all documents\n",
    "\n",
    "data = {}\n",
    "vocab_dict = {}\n",
    "for folder in folders:\n",
    "    data[folder] = []\n",
    "    for doc in os.listdir(os.path.join(mypath, folder)):\n",
    "        with open(os.path.join(mypath, folder,doc), 'r') as f:\n",
    "            text = f.read()\n",
    "            text = text.lower()\n",
    "            # remove any word that has a non alphabetical character\n",
    "            text = re.sub(r'[^a-z]', ' ', text)\n",
    "            temp=text.split()\n",
    "            data[folder].append(temp)\n",
    "            for token in temp:\n",
    "                if token in vocab_dict:\n",
    "                    vocab_dict[token] += 1\n",
    "                elif len(token) >=5 and token not in stopWords:\n",
    "                    vocab_dict[token] = 1\n",
    "                    \n",
    "            \n",
    "\n",
    "len(vocab_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Feature List\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'access',\n",
       " 'actually',\n",
       " 'agate',\n",
       " 'always',\n",
       " 'american',\n",
       " 'andrew',\n",
       " 'another',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'apple',\n",
       " 'around',\n",
       " 'article',\n",
       " 'atheism',\n",
       " 'athos',\n",
       " 'autos',\n",
       " 'available',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'believe',\n",
       " 'berkeley',\n",
       " 'better',\n",
       " 'called',\n",
       " 'cantaloupe',\n",
       " 'center',\n",
       " 'change',\n",
       " 'children',\n",
       " 'christian',\n",
       " 'clipper',\n",
       " 'colorado',\n",
       " 'columbia',\n",
       " 'computer',\n",
       " 'control',\n",
       " 'could',\n",
       " 'course',\n",
       " 'crabapple',\n",
       " 'crypt',\n",
       " 'culture',\n",
       " 'darwin',\n",
       " 'david',\n",
       " 'different',\n",
       " 'distribution',\n",
       " 'drive',\n",
       " 'either',\n",
       " 'electronics',\n",
       " 'email',\n",
       " 'enough',\n",
       " 'europa',\n",
       " 'every',\n",
       " 'evidence',\n",
       " 'example',\n",
       " 'files',\n",
       " 'first',\n",
       " 'following',\n",
       " 'followup',\n",
       " 'forsale',\n",
       " 'found',\n",
       " 'games',\n",
       " 'gatech',\n",
       " 'general',\n",
       " 'geneva',\n",
       " 'getting',\n",
       " 'given',\n",
       " 'going',\n",
       " 'government',\n",
       " 'graphics',\n",
       " 'great',\n",
       " 'group',\n",
       " 'gtefsd',\n",
       " 'hardware',\n",
       " 'harvard',\n",
       " 'heard',\n",
       " 'history',\n",
       " 'hockey',\n",
       " 'however',\n",
       " 'howland',\n",
       " 'human',\n",
       " 'image',\n",
       " 'information',\n",
       " 'internet',\n",
       " 'israel',\n",
       " 'jesus',\n",
       " 'jewish',\n",
       " 'keywords',\n",
       " 'least',\n",
       " 'lines',\n",
       " 'little',\n",
       " 'local',\n",
       " 'looking',\n",
       " 'magnesium',\n",
       " 'makes',\n",
       " 'maybe',\n",
       " 'means',\n",
       " 'message',\n",
       " 'michael',\n",
       " 'mideast',\n",
       " 'might',\n",
       " 'national',\n",
       " 'netcom',\n",
       " 'network',\n",
       " 'never',\n",
       " 'newsgroups',\n",
       " 'nothing',\n",
       " 'number',\n",
       " 'opinions',\n",
       " 'order',\n",
       " 'organization',\n",
       " 'others',\n",
       " 'people',\n",
       " 'person',\n",
       " 'phone',\n",
       " 'place',\n",
       " 'please',\n",
       " 'point',\n",
       " 'politics',\n",
       " 'possible',\n",
       " 'posting',\n",
       " 'power',\n",
       " 'president',\n",
       " 'price',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'program',\n",
       " 'public',\n",
       " 'purdue',\n",
       " 'question',\n",
       " 'questions',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'references',\n",
       " 'religion',\n",
       " 'remember',\n",
       " 'reply',\n",
       " 'research',\n",
       " 'reston',\n",
       " 'right',\n",
       " 'rights',\n",
       " 'rochester',\n",
       " 'rutgers',\n",
       " 'saying',\n",
       " 'science',\n",
       " 'second',\n",
       " 'security',\n",
       " 'seems',\n",
       " 'sender',\n",
       " 'server',\n",
       " 'service',\n",
       " 'several',\n",
       " 'since',\n",
       " 'software',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'source',\n",
       " 'space',\n",
       " 'sport',\n",
       " 'standard',\n",
       " 'stanford',\n",
       " 'start',\n",
       " 'state',\n",
       " 'steve',\n",
       " 'still',\n",
       " 'subject',\n",
       " 'support',\n",
       " 'system',\n",
       " 'systems',\n",
       " 'technology',\n",
       " 'thanks',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'three',\n",
       " 'times',\n",
       " 'today',\n",
       " 'toronto',\n",
       " 'trying',\n",
       " 'turkish',\n",
       " 'university',\n",
       " 'usenet',\n",
       " 'using',\n",
       " 'utexas',\n",
       " 'uunet',\n",
       " 'version',\n",
       " 'virginia',\n",
       " 'wanted',\n",
       " 'washington',\n",
       " 'whether',\n",
       " 'window',\n",
       " 'windows',\n",
       " 'without',\n",
       " 'world',\n",
       " 'would',\n",
       " 'writes',\n",
       " 'wrong',\n",
       " 'wrote',\n",
       " 'years',\n",
       " 'zaphod'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the dictionary based on frequency of each 'possible' vocabulary word\n",
    "sorted_vocab=sorted(vocab_dict.items(),key=operator.itemgetter(1),reverse=True)\n",
    "# Choosing top 2000 vocab words as features\n",
    "feature_list=[]\n",
    "for key in sorted_vocab:\n",
    "    feature_list.append(key[0])\n",
    "feature_list=feature_list[0:200] # K = 200 (number of words in vocab)\n",
    "feature_list = set(feature_list)\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    '''\n",
    "    return : a dataframe of columns as features and rows as documents\n",
    "    '''\n",
    "    df = pd.DataFrame(columns = feature_list)\n",
    "    Y=[]\n",
    "    for folder in folders:\n",
    "        for doc in data[folder]:\n",
    "            Y.append(folder)\n",
    "            # Add a new row for every file\n",
    "            df.loc[len(df)] = np.zeros(len(feature_list))\n",
    "            for txt in doc:\n",
    "                for word in txt.split():\n",
    "                    if word in feature_list:\n",
    "                        df.loc[len(df)-1,word] += 1\n",
    "        \n",
    "    # add Y as a column to dataframe\n",
    "    df['Y']=Y\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Test Data and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>something</th>\n",
       "      <th>though</th>\n",
       "      <th>network</th>\n",
       "      <th>michael</th>\n",
       "      <th>thing</th>\n",
       "      <th>remember</th>\n",
       "      <th>looking</th>\n",
       "      <th>maybe</th>\n",
       "      <th>means</th>\n",
       "      <th>...</th>\n",
       "      <th>games</th>\n",
       "      <th>science</th>\n",
       "      <th>might</th>\n",
       "      <th>forsale</th>\n",
       "      <th>evidence</th>\n",
       "      <th>could</th>\n",
       "      <th>program</th>\n",
       "      <th>given</th>\n",
       "      <th>others</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sender  something  though  network  michael  thing  remember  looking  \\\n",
       "0     0.0        0.0     0.0      0.0      1.0    0.0       0.0      0.0   \n",
       "1     0.0       15.0     3.0      0.0      0.0    9.0       1.0      1.0   \n",
       "2     2.0        1.0     0.0      0.0      0.0    0.0       0.0      0.0   \n",
       "3     0.0        0.0     0.0      0.0      0.0    0.0       0.0      0.0   \n",
       "4     1.0        0.0     0.0      0.0      0.0    0.0       0.0      0.0   \n",
       "\n",
       "   maybe  means  ...  games  science  might  forsale  evidence  could  \\\n",
       "0    0.0    0.0  ...    0.0      0.0    0.0      0.0       0.0    0.0   \n",
       "1    1.0    5.0  ...    0.0      5.0    6.0      0.0       6.0    2.0   \n",
       "2    0.0    0.0  ...    0.0      0.0    1.0      0.0       4.0    1.0   \n",
       "3    0.0    0.0  ...    0.0      0.0    0.0      0.0       0.0    0.0   \n",
       "4    0.0    0.0  ...    0.0      0.0    0.0      0.0       0.0    0.0   \n",
       "\n",
       "   program  given  others            Y  \n",
       "0      0.0    0.0     0.0  alt.atheism  \n",
       "1      0.0    0.0     7.0  alt.atheism  \n",
       "2      0.0    0.0     0.0  alt.atheism  \n",
       "3      0.0    0.0     0.0  alt.atheism  \n",
       "4      0.0    0.0     0.0  alt.atheism  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['Y'],axis=1).values\n",
    "#remove last column of X\n",
    "\n",
    "Y = df['Y'].values\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the last column of df\n",
    "last = df.iloc[:,-1]\n",
    "# divide each row of df by sum of all values in that row except the last column\n",
    "new_df = df.drop(['Y'],axis=1)\n",
    "new_df = new_df.div(new_df.sum(axis=1), axis=0)\n",
    "df = pd.concat([new_df, last], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,random_state=0,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'talk.politics.misc': 741,\n",
       "         'talk.religion.misc': 764,\n",
       "         'sci.electronics': 756,\n",
       "         'misc.forsale': 739,\n",
       "         'rec.motorcycles': 716,\n",
       "         'comp.sys.mac.hardware': 764,\n",
       "         'rec.sport.hockey': 769,\n",
       "         'talk.politics.mideast': 719,\n",
       "         'soc.religion.christian': 745,\n",
       "         'sci.med': 744,\n",
       "         'comp.os.ms-windows.misc': 751,\n",
       "         'talk.politics.guns': 751,\n",
       "         'alt.atheism': 767,\n",
       "         'comp.graphics': 747,\n",
       "         'comp.sys.ibm.pc.hardware': 760,\n",
       "         'rec.sport.baseball': 752,\n",
       "         'sci.crypt': 767,\n",
       "         'rec.autos': 731,\n",
       "         'sci.space': 754,\n",
       "         'comp.windows.x': 760})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count each distinct element in the y_train\n",
    "from collections import Counter\n",
    "Counter(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the inbuilt Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.767"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf=MultinomialNB()\n",
    "clf.fit(x_train,y_train)\n",
    "clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism 0.05114356204574248\n",
      "comp.graphics 0.04980996199239848\n",
      "comp.os.ms-windows.misc 0.05007668200306728\n",
      "comp.sys.ibm.pc.hardware 0.05067680202707208\n",
      "comp.sys.mac.hardware 0.050943522037740885\n",
      "comp.windows.x 0.05067680202707208\n",
      "misc.forsale 0.04927652197106088\n",
      "rec.autos 0.04874308194972328\n",
      "rec.motorcycles 0.047742881909715276\n",
      "rec.sport.baseball 0.05014336200573448\n",
      "rec.sport.hockey 0.05127692205107688\n",
      "sci.crypt 0.05114356204574248\n",
      "sci.electronics 0.05041008201640328\n",
      "sci.med 0.04960992198439688\n",
      "sci.space 0.05027672201106888\n",
      "soc.religion.christian 0.04967660198706408\n",
      "talk.politics.guns 0.05007668200306728\n",
      "talk.politics.mideast 0.047942921917716874\n",
      "talk.politics.misc 0.04940988197639528\n",
      "talk.religion.misc 0.050943522037740885\n"
     ]
    }
   ],
   "source": [
    "# calculate priors for each type of folder\n",
    "priors ={}\n",
    "for folder in folders:\n",
    "    priors[folder] = len(y_train[y_train==folder]) / len(y_train)\n",
    "    print(folder,priors[folder])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004522684435326599"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word= 'example'\n",
    "folder=folders[0]\n",
    "(df[word][df['Y']==folder].sum() + 1) / (len(df[df['Y']==folder]) + len(feature_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>something</th>\n",
       "      <th>though</th>\n",
       "      <th>network</th>\n",
       "      <th>michael</th>\n",
       "      <th>thing</th>\n",
       "      <th>remember</th>\n",
       "      <th>looking</th>\n",
       "      <th>maybe</th>\n",
       "      <th>means</th>\n",
       "      <th>...</th>\n",
       "      <th>however</th>\n",
       "      <th>games</th>\n",
       "      <th>science</th>\n",
       "      <th>might</th>\n",
       "      <th>forsale</th>\n",
       "      <th>evidence</th>\n",
       "      <th>could</th>\n",
       "      <th>program</th>\n",
       "      <th>given</th>\n",
       "      <th>others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011946</td>\n",
       "      <td>0.006935</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003680</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.005650</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.003860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015882</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.007179</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.006615</td>\n",
       "      <td>0.008322</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.001596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015209</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.002323</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.001785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015592</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.006040</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.002060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.006215</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.001297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sender  something    though   network   michael     thing  remember  \\\n",
       "0  0.011946   0.006935  0.003031  0.001789  0.001908  0.005161  0.002263   \n",
       "1  0.015882   0.003801  0.001822  0.003676  0.002449  0.002308  0.001329   \n",
       "2  0.015209   0.004574  0.002569  0.004266  0.002988  0.002323  0.002124   \n",
       "3  0.015592   0.003870  0.002397  0.003683  0.003789  0.002912  0.001680   \n",
       "4  0.016804   0.003792  0.002431  0.004377  0.002951  0.002932  0.001843   \n",
       "\n",
       "    looking     maybe     means  ...   however     games   science     might  \\\n",
       "0  0.001620  0.002522  0.003702  ...  0.003680  0.000892  0.007494  0.003866   \n",
       "1  0.007179  0.001696  0.001527  ...  0.002188  0.001276  0.004004  0.002467   \n",
       "2  0.003674  0.002290  0.001563  ...  0.002651  0.001321  0.002357  0.002201   \n",
       "3  0.003233  0.002070  0.001826  ...  0.002853  0.001558  0.002716  0.003069   \n",
       "4  0.003024  0.001743  0.001847  ...  0.002499  0.001580  0.002615  0.003062   \n",
       "\n",
       "    forsale  evidence     could   program     given    others  \n",
       "0  0.000833  0.005650  0.008492  0.001242  0.003236  0.003860  \n",
       "1  0.000887  0.000895  0.006615  0.008322  0.002288  0.001596  \n",
       "2  0.000935  0.000877  0.004398  0.008624  0.001129  0.001785  \n",
       "3  0.001687  0.000983  0.006040  0.004160  0.001172  0.002060  \n",
       "4  0.001824  0.000997  0.006215  0.002021  0.001504  0.001297  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate class conditional probabilities p(x|y) where x is a word and y is a newsgroup for each word in the vocabulary as a dataframe\n",
    "conditional_probabilities = pd.DataFrame(columns=feature_list)\n",
    "i=0;\n",
    "for folder in folders:\n",
    "    # add a new row for each folder\n",
    "    conditional_probabilities.loc[len(conditional_probabilities)] = np.zeros(len(feature_list))\n",
    "    # use df calculated above to calculate conditional probabilities\n",
    "    for word in feature_list:\n",
    "        #print(word)\n",
    "        conditional_probabilities[word][i] = (df[word][df['Y']==folder].sum() + 1) / (len(df[df['Y']==folder]) + len(feature_list))\n",
    "    i+=1\n",
    "conditional_probabilities.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sender       1.0\n",
       "something    1.0\n",
       "though       1.0\n",
       "network      1.0\n",
       "michael      1.0\n",
       "            ... \n",
       "evidence     1.0\n",
       "could        1.0\n",
       "program      1.0\n",
       "given        1.0\n",
       "others       1.0\n",
       "Length: 200, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize each columns of conditional_probabilities\n",
    "conditional_probabilities = conditional_probabilities.div(conditional_probabilities.sum(axis=0), axis=1)\n",
    "# get the sum of each column\n",
    "conditional_probabilities.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a={'a':1,'b':2,'c':3}\n",
    "max(a,key=a.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    # calculate the probability of each word in the text belonging to each newsgroup\n",
    "    probabilities = {}\n",
    "    i=0\n",
    "    for f_in in range(len(folders)):\n",
    "        probabilities[folders[f_in]] = np.log(priors[folders[f_in]])\n",
    "        for i in range(len(text)):\n",
    "            probabilities[folders[f_in]] += np.log(conditional_probabilities.values[f_in][i])*text[i]\n",
    "    # return the newsgroup with the highest probability\n",
    "    # print(probabilities)\n",
    "    return max(probabilities, key=probabilities.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data(x_test):\n",
    "    predictions = []\n",
    "    for i in range(len(x_test)):\n",
    "        print(':',end=\" \")\n",
    "        predictions.append(predict(x_test[i]))\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "y_pred=predict_data(x_test)\n",
    "# print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7962"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred==y_test)/len(y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74fc0cb1932bf4b202d61f4ecf9d651fa79ff967900f756d776817a87c2d0209"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
