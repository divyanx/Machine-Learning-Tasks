{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from network import Network\n",
    "\n",
    "from fullyconnlayer import FullyConnLayer\n",
    "from activation_layer import ActivationFuncLayer\n",
    "from activations import linear,linear_prime\n",
    "from losses import mse, mse_prime\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.320e-03 1.800e+01 2.310e+00 0.000e+00 5.380e-01 6.575e+00 6.520e+01\n",
      "  4.090e+00 1.000e+00 2.960e+02 1.530e+01 3.969e+02 4.980e+00]]\n",
      "[[24.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAZORBLADE\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "from sklearn.datasets import load_boston\n",
    "# training data\n",
    "x_train, y_train = load_boston(return_X_y=True)\n",
    "# # standarise x and y\n",
    "\n",
    "\n",
    "# print(x_train)\n",
    "# print(y_train)\n",
    "\n",
    "x_train = np.expand_dims(x_train,axis=1)\n",
    "y_train = y_train.reshape(y_train.shape[0],1)\n",
    "y_train = np.expand_dims(y_train,axis=1)\n",
    "\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just one output neural with linear activation and least mean square loss.\n",
    "# (This is linear regression).\n",
    "# • two layers. Layer 1 with 13 output neurons with sigmoid activation. Layer\n",
    "# 2 with one output neuron and linear activation. use mean squared loss\n",
    "# • three layers. Layer 1 with 13 output neurons with sigmoid activation.\n",
    "# Layer 2 with 13 output neurons and sigmoid activation. Layer 3 with one\n",
    "# output neuron and linear activation. use mean squared loss\n",
    "# network\n",
    "net = Network()\n",
    "net.insert(FullyConnLayer(13, 13))\n",
    "net.insert(ActivationFuncLayer(linear, linear_prime))\n",
    "# net.insert(Layer(30, 30))\n",
    "# net.insert(ActivationFuncLayer(tanh, tanh_prime))\n",
    "net.insert(FullyConnLayer(13, 1))\n",
    "net.insert(ActivationFuncLayer(linear, linear_prime))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/1000   error=548.081318\n",
      "epoch 2/1000   error=548.081318\n",
      "epoch 3/1000   error=548.081318\n",
      "epoch 4/1000   error=548.081318\n",
      "epoch 5/1000   error=548.081318\n",
      "epoch 6/1000   error=548.081318\n",
      "epoch 7/1000   error=548.081318\n",
      "epoch 8/1000   error=548.081318\n",
      "epoch 9/1000   error=548.081318\n",
      "epoch 10/1000   error=548.081318\n",
      "epoch 11/1000   error=548.081318\n",
      "epoch 12/1000   error=548.081318\n",
      "epoch 13/1000   error=548.081318\n",
      "epoch 14/1000   error=548.081318\n",
      "epoch 15/1000   error=548.081318\n",
      "epoch 16/1000   error=548.081318\n",
      "epoch 17/1000   error=548.081318\n",
      "epoch 18/1000   error=548.081318\n",
      "epoch 19/1000   error=548.081318\n",
      "epoch 20/1000   error=548.081318\n",
      "epoch 21/1000   error=548.081318\n",
      "epoch 22/1000   error=548.081318\n",
      "epoch 23/1000   error=548.081318\n",
      "epoch 24/1000   error=548.081318\n",
      "epoch 25/1000   error=548.081318\n",
      "epoch 26/1000   error=548.081318\n",
      "epoch 27/1000   error=548.081318\n",
      "epoch 28/1000   error=548.081318\n",
      "epoch 29/1000   error=548.081318\n",
      "epoch 30/1000   error=548.081318\n",
      "epoch 31/1000   error=548.081318\n",
      "epoch 32/1000   error=548.081318\n",
      "epoch 33/1000   error=548.081318\n",
      "epoch 34/1000   error=548.081318\n",
      "epoch 35/1000   error=548.081318\n",
      "epoch 36/1000   error=548.081318\n",
      "epoch 37/1000   error=548.081318\n",
      "epoch 38/1000   error=548.081318\n",
      "epoch 39/1000   error=548.081318\n",
      "epoch 40/1000   error=548.081318\n",
      "epoch 41/1000   error=548.081318\n",
      "epoch 42/1000   error=548.081318\n",
      "epoch 43/1000   error=548.081318\n",
      "epoch 44/1000   error=548.081318\n",
      "epoch 45/1000   error=548.081318\n",
      "epoch 46/1000   error=548.081318\n",
      "epoch 47/1000   error=548.081318\n",
      "epoch 48/1000   error=548.081318\n",
      "epoch 49/1000   error=548.081318\n",
      "epoch 50/1000   error=548.081318\n",
      "epoch 51/1000   error=548.081318\n",
      "epoch 52/1000   error=548.081318\n",
      "epoch 53/1000   error=548.081318\n",
      "epoch 54/1000   error=548.081318\n",
      "epoch 55/1000   error=548.081318\n",
      "epoch 56/1000   error=548.081318\n",
      "epoch 57/1000   error=548.081318\n",
      "epoch 58/1000   error=548.081318\n",
      "epoch 59/1000   error=548.081318\n",
      "epoch 60/1000   error=548.081318\n",
      "epoch 61/1000   error=548.081318\n",
      "epoch 62/1000   error=548.081318\n",
      "epoch 63/1000   error=548.081318\n",
      "epoch 64/1000   error=548.081318\n",
      "epoch 65/1000   error=548.081318\n",
      "epoch 66/1000   error=548.081318\n",
      "epoch 67/1000   error=548.081318\n",
      "epoch 68/1000   error=548.081318\n",
      "epoch 69/1000   error=548.081318\n",
      "epoch 70/1000   error=548.081318\n",
      "epoch 71/1000   error=548.081318\n",
      "epoch 72/1000   error=548.081318\n",
      "epoch 73/1000   error=548.081318\n",
      "epoch 74/1000   error=548.081318\n",
      "epoch 75/1000   error=548.081318\n",
      "epoch 76/1000   error=548.081318\n",
      "epoch 77/1000   error=548.081318\n",
      "epoch 78/1000   error=548.081318\n",
      "epoch 79/1000   error=548.081318\n",
      "epoch 80/1000   error=548.081318\n",
      "epoch 81/1000   error=548.081318\n",
      "epoch 82/1000   error=548.081318\n",
      "epoch 83/1000   error=548.081318\n",
      "epoch 84/1000   error=548.081318\n",
      "epoch 85/1000   error=548.081318\n",
      "epoch 86/1000   error=548.081318\n",
      "epoch 87/1000   error=548.081318\n",
      "epoch 88/1000   error=548.081318\n",
      "epoch 89/1000   error=548.081318\n",
      "epoch 90/1000   error=548.081318\n",
      "epoch 91/1000   error=548.081318\n",
      "epoch 92/1000   error=548.081318\n",
      "epoch 93/1000   error=548.081318\n",
      "epoch 94/1000   error=548.081318\n",
      "epoch 95/1000   error=548.081318\n",
      "epoch 96/1000   error=548.081318\n",
      "epoch 97/1000   error=548.081318\n",
      "epoch 98/1000   error=548.081318\n",
      "epoch 99/1000   error=548.081318\n",
      "epoch 100/1000   error=548.081318\n",
      "epoch 101/1000   error=548.081318\n",
      "epoch 102/1000   error=548.081318\n",
      "epoch 103/1000   error=548.081317\n",
      "epoch 104/1000   error=548.081317\n",
      "epoch 105/1000   error=548.081317\n",
      "epoch 106/1000   error=548.081317\n",
      "epoch 107/1000   error=548.081317\n",
      "epoch 108/1000   error=548.081317\n",
      "epoch 109/1000   error=548.081317\n",
      "epoch 110/1000   error=548.081317\n",
      "epoch 111/1000   error=548.081317\n",
      "epoch 112/1000   error=548.081317\n",
      "epoch 113/1000   error=548.081317\n",
      "epoch 114/1000   error=548.081317\n",
      "epoch 115/1000   error=548.081317\n",
      "epoch 116/1000   error=548.081317\n",
      "epoch 117/1000   error=548.081317\n",
      "epoch 118/1000   error=548.081317\n",
      "epoch 119/1000   error=548.081317\n",
      "epoch 120/1000   error=548.081317\n",
      "epoch 121/1000   error=548.081317\n",
      "epoch 122/1000   error=548.081317\n",
      "epoch 123/1000   error=548.081317\n",
      "epoch 124/1000   error=548.081317\n",
      "epoch 125/1000   error=548.081317\n",
      "epoch 126/1000   error=548.081317\n",
      "epoch 127/1000   error=548.081317\n",
      "epoch 128/1000   error=548.081317\n",
      "epoch 129/1000   error=548.081317\n",
      "epoch 130/1000   error=548.081317\n",
      "epoch 131/1000   error=548.081317\n",
      "epoch 132/1000   error=548.081317\n",
      "epoch 133/1000   error=548.081317\n",
      "epoch 134/1000   error=548.081317\n",
      "epoch 135/1000   error=548.081317\n",
      "epoch 136/1000   error=548.081317\n",
      "epoch 137/1000   error=548.081317\n",
      "epoch 138/1000   error=548.081317\n",
      "epoch 139/1000   error=548.081317\n",
      "epoch 140/1000   error=548.081317\n",
      "epoch 141/1000   error=548.081317\n",
      "epoch 142/1000   error=548.081317\n",
      "epoch 143/1000   error=548.081317\n",
      "epoch 144/1000   error=548.081317\n",
      "epoch 145/1000   error=548.081317\n",
      "epoch 146/1000   error=548.081317\n",
      "epoch 147/1000   error=548.081317\n",
      "epoch 148/1000   error=548.081317\n",
      "epoch 149/1000   error=548.081317\n",
      "epoch 150/1000   error=548.081317\n",
      "epoch 151/1000   error=548.081317\n",
      "epoch 152/1000   error=548.081317\n",
      "epoch 153/1000   error=548.081317\n",
      "epoch 154/1000   error=548.081317\n",
      "epoch 155/1000   error=548.081317\n",
      "epoch 156/1000   error=548.081317\n",
      "epoch 157/1000   error=548.081317\n",
      "epoch 158/1000   error=548.081317\n",
      "epoch 159/1000   error=548.081317\n",
      "epoch 160/1000   error=548.081317\n",
      "epoch 161/1000   error=548.081317\n",
      "epoch 162/1000   error=548.081317\n",
      "epoch 163/1000   error=548.081317\n",
      "epoch 164/1000   error=548.081317\n",
      "epoch 165/1000   error=548.081317\n",
      "epoch 166/1000   error=548.081317\n",
      "epoch 167/1000   error=548.081317\n",
      "epoch 168/1000   error=548.081317\n",
      "epoch 169/1000   error=548.081317\n",
      "epoch 170/1000   error=548.081317\n",
      "epoch 171/1000   error=548.081317\n",
      "epoch 172/1000   error=548.081317\n",
      "epoch 173/1000   error=548.081317\n",
      "epoch 174/1000   error=548.081317\n",
      "epoch 175/1000   error=548.081317\n",
      "epoch 176/1000   error=548.081317\n",
      "epoch 177/1000   error=548.081317\n",
      "epoch 178/1000   error=548.081317\n",
      "epoch 179/1000   error=548.081317\n",
      "epoch 180/1000   error=548.081317\n",
      "epoch 181/1000   error=548.081317\n",
      "epoch 182/1000   error=548.081317\n",
      "epoch 183/1000   error=548.081317\n",
      "epoch 184/1000   error=548.081317\n",
      "epoch 185/1000   error=548.081317\n",
      "epoch 186/1000   error=548.081317\n",
      "epoch 187/1000   error=548.081317\n",
      "epoch 188/1000   error=548.081317\n",
      "epoch 189/1000   error=548.081317\n",
      "epoch 190/1000   error=548.081317\n",
      "epoch 191/1000   error=548.081317\n",
      "epoch 192/1000   error=548.081317\n",
      "epoch 193/1000   error=548.081317\n",
      "epoch 194/1000   error=548.081317\n",
      "epoch 195/1000   error=548.081317\n",
      "epoch 196/1000   error=548.081317\n",
      "epoch 197/1000   error=548.081317\n",
      "epoch 198/1000   error=548.081317\n",
      "epoch 199/1000   error=548.081317\n",
      "epoch 200/1000   error=548.081317\n",
      "epoch 201/1000   error=548.081317\n",
      "epoch 202/1000   error=548.081317\n",
      "epoch 203/1000   error=548.081317\n",
      "epoch 204/1000   error=548.081317\n",
      "epoch 205/1000   error=548.081317\n",
      "epoch 206/1000   error=548.081317\n",
      "epoch 207/1000   error=548.081317\n",
      "epoch 208/1000   error=548.081317\n",
      "epoch 209/1000   error=548.081317\n",
      "epoch 210/1000   error=548.081317\n",
      "epoch 211/1000   error=548.081317\n",
      "epoch 212/1000   error=548.081317\n",
      "epoch 213/1000   error=548.081317\n",
      "epoch 214/1000   error=548.081317\n",
      "epoch 215/1000   error=548.081317\n",
      "epoch 216/1000   error=548.081317\n",
      "epoch 217/1000   error=548.081317\n",
      "epoch 218/1000   error=548.081317\n",
      "epoch 219/1000   error=548.081317\n",
      "epoch 220/1000   error=548.081317\n",
      "epoch 221/1000   error=548.081317\n",
      "epoch 222/1000   error=548.081317\n",
      "epoch 223/1000   error=548.081317\n",
      "epoch 224/1000   error=548.081317\n",
      "epoch 225/1000   error=548.081317\n",
      "epoch 226/1000   error=548.081317\n",
      "epoch 227/1000   error=548.081317\n",
      "epoch 228/1000   error=548.081317\n",
      "epoch 229/1000   error=548.081317\n",
      "epoch 230/1000   error=548.081317\n",
      "epoch 231/1000   error=548.081317\n",
      "epoch 232/1000   error=548.081317\n",
      "epoch 233/1000   error=548.081317\n",
      "epoch 234/1000   error=548.081317\n",
      "epoch 235/1000   error=548.081317\n",
      "epoch 236/1000   error=548.081317\n",
      "epoch 237/1000   error=548.081317\n",
      "epoch 238/1000   error=548.081317\n",
      "epoch 239/1000   error=548.081317\n",
      "epoch 240/1000   error=548.081317\n",
      "epoch 241/1000   error=548.081317\n",
      "epoch 242/1000   error=548.081317\n",
      "epoch 243/1000   error=548.081317\n",
      "epoch 244/1000   error=548.081317\n",
      "epoch 245/1000   error=548.081317\n",
      "epoch 246/1000   error=548.081317\n",
      "epoch 247/1000   error=548.081317\n",
      "epoch 248/1000   error=548.081317\n",
      "epoch 249/1000   error=548.081317\n",
      "epoch 250/1000   error=548.081317\n",
      "epoch 251/1000   error=548.081317\n",
      "epoch 252/1000   error=548.081317\n",
      "epoch 253/1000   error=548.081317\n",
      "epoch 254/1000   error=548.081317\n",
      "epoch 255/1000   error=548.081317\n",
      "epoch 256/1000   error=548.081317\n",
      "epoch 257/1000   error=548.081317\n",
      "epoch 258/1000   error=548.081317\n",
      "epoch 259/1000   error=548.081317\n",
      "epoch 260/1000   error=548.081317\n",
      "epoch 261/1000   error=548.081317\n",
      "epoch 262/1000   error=548.081317\n",
      "epoch 263/1000   error=548.081317\n",
      "epoch 264/1000   error=548.081317\n",
      "epoch 265/1000   error=548.081317\n",
      "epoch 266/1000   error=548.081317\n",
      "epoch 267/1000   error=548.081317\n",
      "epoch 268/1000   error=548.081317\n",
      "epoch 269/1000   error=548.081317\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\RAZORBLADE\\Desktop\\Sem-VI\\CS331 - ML\\Machine-Learning-Tasks\\Machine-Learning-Tasks\\Assignment-04\\NeuralNet\\Q5.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/Q5.ipynb#ch0000008?line=0'>1</a>\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/Q5.ipynb#ch0000008?line=1'>2</a>\u001b[0m \u001b[39m# net.employ(mse, mse_prime)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/Q5.ipynb#ch0000008?line=2'>3</a>\u001b[0m net\u001b[39m.\u001b[39memploy(mse, mse_prime)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/Q5.ipynb#ch0000008?line=3'>4</a>\u001b[0m net\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\RAZORBLADE\\Desktop\\Sem-VI\\CS331 - ML\\Machine-Learning-Tasks\\Machine-Learning-Tasks\\Assignment-04\\NeuralNet\\network.py:52\u001b[0m, in \u001b[0;36mNetwork.fit\u001b[1;34m(self, x_train, y_train, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/network.py?line=49'>50</a>\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mder_loss(y_train[j], out)\n\u001b[0;32m     <a href='file:///c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/network.py?line=50'>51</a>\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers):\n\u001b[1;32m---> <a href='file:///c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/network.py?line=51'>52</a>\u001b[0m         error \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mback_pass(error, learning_rate)\n\u001b[0;32m     <a href='file:///c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/network.py?line=53'>54</a>\u001b[0m \u001b[39m# calculate average error on all input data\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/network.py?line=54'>55</a>\u001b[0m mistake \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m in_data\n",
      "File \u001b[1;32mc:\\Users\\RAZORBLADE\\Desktop\\Sem-VI\\CS331 - ML\\Machine-Learning-Tasks\\Machine-Learning-Tasks\\Assignment-04\\NeuralNet\\fullyconnlayer.py:21\u001b[0m, in \u001b[0;36mFullyConnLayer.back_pass\u001b[1;34m(self, out_error, learning_rate)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/fullyconnlayer.py?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mback_pass\u001b[39m(\u001b[39mself\u001b[39m, out_error, learning_rate):\n\u001b[0;32m     <a href='file:///c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/fullyconnlayer.py?line=19'>20</a>\u001b[0m     in_error \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(out_error, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights\u001b[39m.\u001b[39mT)\n\u001b[1;32m---> <a href='file:///c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/fullyconnlayer.py?line=20'>21</a>\u001b[0m     err_in_weights \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput\u001b[39m.\u001b[39;49mT, out_error)\n\u001b[0;32m     <a href='file:///c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/fullyconnlayer.py?line=21'>22</a>\u001b[0m     \u001b[39m# dBias = out_error\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/fullyconnlayer.py?line=22'>23</a>\u001b[0m \n\u001b[0;32m     <a href='file:///c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/fullyconnlayer.py?line=23'>24</a>\u001b[0m     \u001b[39m# update parameters\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-04/NeuralNet/fullyconnlayer.py?line=24'>25</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m learning_rate \u001b[39m*\u001b[39m err_in_weights\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "# net.employ(mse, mse_prime)\n",
    "net.employ(mse, mse_prime)\n",
    "net.fit(x_train, y_train, epochs=1000, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]]), array([[1.]])]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "out = net.predict(x_train)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74fc0cb1932bf4b202d61f4ecf9d651fa79ff967900f756d776817a87c2d0209"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
