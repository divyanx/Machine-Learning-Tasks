{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.datasets import load_iris"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Matrix Multiplication of Feature Matrix and Weight Matrix\n",
                "class Matrix_Multiplication:\n",
                "    def __init__(self,d,N):\n",
                "        self.N = N\n",
                "        self.W = np.zeros([d,N])\n",
                "        self.X = 0\n",
                "    def ForwardPass(self,X):\n",
                "        self.X = X\n",
                "        return np.dot(X,self.W)\n",
                "    def BackwardPass(self,grad):\n",
                "        dw,dx = np.dot(self.X.T,grad),np.dot(grad,self.W.T) \n",
                "        self.W = self.W - 0.000001*dw\n",
                "        return dx\n",
                "\n",
                "# Bias Addition Layer to the Neural Network   \n",
                "class Bias_Layer:\n",
                "    def __init__(self,N):\n",
                "        self.Y = 0\n",
                "        self.B = np.array([np.ones(N)])\n",
                "        self.N = N\n",
                "    def ForwardPass(self,y):\n",
                "        self.Y = y\n",
                "        T = y.T\n",
                "        L = []\n",
                "        for i in range(self.N):\n",
                "            L.append(T[i]+self.B[0][i])\n",
                "        return np.array(L).T\n",
                "\n",
                "    def BackwardPass(self,grad):\n",
                "        dN,dB = grad,sum(grad)\n",
                "        self.B = self.B - 0.000001*dB\n",
                "        return dN\n",
                "\n",
                "# Finding Mean Squared Error   \n",
                "class Mean_Square_Loss:\n",
                "    def __init__(self):\n",
                "        self.Y = 0\n",
                "        self.P = 0\n",
                "    def ForwardPass(self,p,y):\n",
                "        self.P = p\n",
                "        self.Y = y\n",
                "        return sum((p-y)**2)\n",
                "    def BackwardPass(self):\n",
                "        return 2*(self.P - self.Y)\n",
                "\n",
                "# Creating the Softmax Layer, Probability Layer    \n",
                "class Soft_Max:\n",
                "    def __init__(self):\n",
                "        self.Z = 0\n",
                "    def ForwardPass(self,z):\n",
                "        self.Z = z\n",
                "        self.L = 0\n",
                "        L = []\n",
                "        for j in range(len(z)):\n",
                "            L.append([])\n",
                "            for i in range(len(self.Z[j])):\n",
                "                Nemo = np.exp(z[j][i])\n",
                "                Demo = sum(np.exp(z[j]))\n",
                "                L[j].append(Nemo/Demo)\n",
                "        L = np.array(L)\n",
                "        self.L= L\n",
                "        return L\n",
                "    def BackwardPass(self,out):\n",
                "        L = []\n",
                "        for i in range(len(out)):\n",
                "            A = np.zeros([len(self.Z[0]),len(self.Z[0])])\n",
                "            S = self.L\n",
                "            for j in range(len(self.Z[0])):\n",
                "                for k in range(len(self.Z[0])):\n",
                "                    if j == k:\n",
                "                        A[j][k] = S[i][k]*(1-S[i][k])\n",
                "                    else:\n",
                "                        A[j][k] = -S[i][j]*S[i][k]\n",
                "            L.append(np.dot(out[i],A))\n",
                "        return np.array(L)\n",
                "\n",
                "# Sigmoid ActivationFuncLayer Function\n",
                "class Sigmoid:\n",
                "    def __init__(self):\n",
                "        self.Z = 0\n",
                "        self.O = 0\n",
                "    def ForwardPass(self,z):\n",
                "        self.Z = z\n",
                "        self.O = 1/(1+np.exp(-self.z))\n",
                "        return self.O\n",
                "    def BackwardPass(self,grad):\n",
                "        print('Back Input to Sigmoid = ',grad)\n",
                "        S = self.O\n",
                "        return (S*(S-1))*grad\n",
                "\n",
                "# Cross Entropy Loss Function\n",
                "class Cross_Entropy_Loss:\n",
                "    def __init__(self):\n",
                "        self.Y = 0\n",
                "        self.P = 0\n",
                "    def ForwardPass(self,p,y):\n",
                "        self.P = p\n",
                "        self.Y = [y]\n",
                "        L = []\n",
                "        for i in self.P:\n",
                "            L.append(-np.log(i[y]))\n",
                "            # print(i[y])\n",
                "        return sum(L)\n",
                "    def BackwardPass(self):\n",
                "        dL = np.zeros([self.P.shape[0],self.P.shape[1]])\n",
                "        Y =  np.zeros([self.P.shape[0],self.P.shape[1]])\n",
                "        for i in range(len(self.Y)):\n",
                "            Y[i][self.Y[i]] = 1\n",
                "        for i in range(len(dL)):\n",
                "            for j in range(len(dL[0])):\n",
                "                dL[i][j] = -Y[i][j]/self.P[i][j]\n",
                "        return dL"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Loading the Iris Data Set\n",
                "Data_Iris = load_iris()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Converting the Data Set into a Pandas Data Frame\n",
                "iris  = pd.DataFrame(Data_Iris.data, columns=Data_Iris.feature_names)\n",
                "Y = Data_Iris.target\n",
                "iris = iris.drop(['petal width (cm)'],axis=1)\n",
                "X = pd.DataFrame.to_numpy(iris)\n",
                "X = list(map(list,list(X)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "Obj1 = Matrix_Multiplication(len(X[0]),3)\n",
                "Obj2 = Bias_Layer(3)\n",
                "Obj3 = Soft_Max()\n",
                "Obj4 = Cross_Entropy_Loss()\n",
                "itr = 0\n",
                "while( itr < 1000):\n",
                "    for i in range(len(X)):\n",
                "        # forwardpropagation\n",
                "        Out1 = Obj1.ForwardPass(np.array([X[i]]))\n",
                "        Out2 = Obj2.ForwardPass(Out1)\n",
                "        Out3 = Obj3.ForwardPass(Out2)\n",
                "        Out4 = Obj4.ForwardPass(Out3,Y[i])\n",
                "        # backpropagation\n",
                "        dy1 =  Obj4.BackwardPass()\n",
                "        dy2 =  Obj3.BackwardPass(dy1)\n",
                "        dy3 =  Obj2.BackwardPass(dy2)\n",
                "        dy4 =  Obj1.BackwardPass(dy3)\n",
                "    itr+=1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "W = Obj1.W\n",
                "B = Obj2.B\n",
                "L = []\n",
                "for i in range(len(X)):\n",
                "    Soft2 = Soft_Max()\n",
                "    Out = Soft2.ForwardPass((np.dot(np.array([X[i]]),W).T+B.T).T)\n",
                "    Out = list(Out[0])\n",
                "    L.append(Out.index(max(Out)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Count of Wrong Prediction : 76\n"
                    ]
                }
            ],
            "source": [
                "errorCnt =0 \n",
                "for i in range(len(Y)):\n",
                "    if Y[i] != L[i]:\n",
                "        errorCnt+=1\n",
                "print('Count of Wrong Prediction :',errorCnt)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
        },
        "kernelspec": {
            "display_name": "Python 3.10.0 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}