{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LassoGD(y, tx, initial_w, lambda_, max_iters, gamma):\n",
    "    \"\"\"Gradient descent algorithm for Lasso\"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute gradient and loss\n",
    "        grad = compute_gradient_Lasso(y, tx, w, lambda_)\n",
    "        loss = compute_loss_Lasso(y, tx, w, lambda_)\n",
    "        # gradient w by descent update\n",
    "        w = w - gamma * grad\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        # print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
    "        #     bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_Lasso(y, tx, w, lambda_):\n",
    "    \"\"\"Compute the loss.\"\"\"\n",
    "    e = y - tx.dot(w)\n",
    "    loss = np.sum(e**2) / 2 + lambda_ * np.sum(np.abs(w))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_Lasso(y, tx, w, lambda_):\n",
    "    \"\"\"Compute the gradient.\"\"\"\n",
    "    e = y - tx.dot(w)\n",
    "    grad = -tx.T.dot(e) + lambda_ * np.sign(w)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RidgeGD(y, tx, initial_w, lambda_, max_iters, gamma):\n",
    "    \"\"\"Gradient descent algorithm for Ridge\"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute gradient and loss\n",
    "        grad = compute_gradient_Ridge(y, tx, w, lambda_)\n",
    "        loss = compute_loss_Ridge(y, tx, w, lambda_)\n",
    "        # gradient w by descent update\n",
    "        print(\"grad = \",grad)\n",
    "        print(\"gamma = \",gamma)\n",
    "        #convert tuple to list\n",
    "        grad = list(grad)\n",
    "        \n",
    "        #multiply each element of the gradient by gamma\n",
    "        for i in range(len(grad)):\n",
    "            grad[i] = grad[i] * gamma\n",
    "        w = w - grad\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        # print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
    "        #     bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_Ridge(y, tx, w, lambda_):\n",
    "    \"\"\"Compute the gradient.\"\"\"\n",
    "    e = y - tx.dot(w)\n",
    "    grad = -tx.T.dot(e) + lambda_ * w\n",
    "    return grad, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_Ridge(y, tx, w, lambda_):\n",
    "    \"\"\"Compute the loss.\"\"\"\n",
    "    e = y - tx.dot(w)\n",
    "    loss = np.sum(e**2) / 2 + lambda_ * np.sum(w**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ElasticNetGD(y, tx, initial_w, lambda_, max_iters, gamma, alpha):\n",
    "    \"\"\"Gradient descent algorithm for Elastic Net\"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # compute gradient and loss\n",
    "        grad = compute_gradient_ElasticNet(y, tx, w, lambda_, alpha)\n",
    "        loss = compute_loss_ElasticNet(y, tx, w, lambda_, alpha)\n",
    "        # gradient w by descent update\n",
    "        \n",
    "        w = w - gamma * grad\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        # print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
    "        #     bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_ElasticNet(y, tx, w, lambda_, alpha):\n",
    "    \"\"\"Compute the loss.\"\"\"\n",
    "    e = y - tx.dot(w)\n",
    "    loss = np.sum(e**2) / 2 + lambda_ * (alpha * np.sum(np.abs(w)) + (1 - alpha) * np.sum(w**2)/2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_ElasticNet(y, tx, w, lambda_, alpha):\n",
    "    \"\"\"Compute the gradient.\"\"\"\n",
    "    e = y - tx.dot(w)\n",
    "    grad = -tx.T.dot(e) + lambda_ * (alpha * np.sign(w) + (1 - alpha) * w)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidate(y, tx, k_fold, lambda_, max_iters, gamma, alpha):\n",
    "    \"\"\" returns losses for each regularisation\n",
    "    i.e Lasso, Ridge, Elastic Net\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    weights = []\n",
    "    for i in range(k_fold):\n",
    "        # split data into training and test set\n",
    "        y_train = y[i*len(y)//k_fold:(i+1)*len(y)//k_fold]\n",
    "        y_test_1 = y[:i*len(y)//k_fold] \n",
    "        y_test_2 = y[(i+1)*len(y)//k_fold:]\n",
    "        y_test = np.concatenate((y_test_1, y_test_2))\n",
    "        # y_train, y_test = y[i*len(y)//k_fold:(i+1)*len(y)//k_fold], y[:i*len(y)//k_fold] + y[(i+1)*len(y)//k_fold:]\n",
    "        # tx_train, tx_test = tx[i*len(tx)//k_fold:(i+1)*len(tx)//k_fold], tx[:i*len(tx)//k_fold] + tx[(i+1)*len(tx)//k_fold:]\n",
    "        tx_train = tx[i*len(tx)//k_fold:(i+1)*len(tx)//k_fold]\n",
    "        tx_test_1 = tx[:i*len(tx)//k_fold]\n",
    "        tx_test_2 = tx[(i+1)*len(tx)//k_fold:]\n",
    "        tx_test = np.concatenate((tx_test_1, tx_test_2))\n",
    "        #choose a gamma\n",
    "        gamma = 0.01\n",
    "        #initilize initial weights\n",
    "        #print(tx_train)\n",
    "        initial_w = np.zeros(tx_train.shape)\n",
    "        #print(initial_w)\n",
    "        # train model and predict\n",
    "        losses_lasso, ws_lasso = LassoGD(y_train, tx_train,initial_w, lambda_, max_iters, gamma)\n",
    "        losses_ridge, ws_ridge = RidgeGD(y_train, tx_train,initial_w, lambda_, max_iters, gamma)\n",
    "        losses_elastic, ws_elastic = ElasticNetGD(y_train, tx_train, initial_w,lambda_, max_iters, gamma, alpha)\n",
    "        # append losses\n",
    "        losses.append(losses_lasso)\n",
    "        losses.append(losses_ridge)\n",
    "        losses.append(losses_elastic)\n",
    "        # append weights\n",
    "        weights.append(ws_lasso)\n",
    "        weights.append(ws_ridge)\n",
    "        weights.append(ws_elastic)\n",
    "\n",
    "    return losses, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 60\n",
    "x = np.random.uniform(0, 10, n)\n",
    "\n",
    "# a be any real number\n",
    "a = 20\n",
    "b = 10\n",
    "e = np.random.normal(0, 1, n)*5\n",
    "\n",
    "y = a * x + b + e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the data\n",
    "# figure size (width, height)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "\n",
    "plt.grid(False)\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Scatter plot of y vs x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAZORBLADE\\AppData\\Local\\Temp\\ipykernel_17240\\912174918.py:4: RuntimeWarning: overflow encountered in square\n",
      "  loss = np.sum(e**2) / 2 + lambda_ * np.sum(np.abs(w))\n",
      "C:\\Users\\RAZORBLADE\\AppData\\Local\\Temp\\ipykernel_17240\\2043934757.py:12: RuntimeWarning: invalid value encountered in subtract\n",
      "  w = w - gamma * grad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad =  (array([-7911.84627763, -7911.84627763, -7911.84627763, -7911.84627763,\n",
      "       -7911.84627763, -7911.84627763, -7911.84627763, -7911.84627763,\n",
      "       -7911.84627763, -7911.84627763]), array([ 91.51354018,  53.96856007, 173.15929707, 180.67003953,\n",
      "       197.12060673,  78.16155206, 174.41894554,  35.49128092,\n",
      "        16.33440741, 135.883407  ]))\n",
      "gamma =  0.01\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (10,) and (2,10) not aligned: 10 (dim 0) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\RAZORBLADE\\Desktop\\Sem-VI\\CS331 - ML\\Machine-Learning-Tasks\\Machine-Learning-Tasks\\Assignment-03\\04-Regularisation\\02-Regularisation.ipynb Cell 14'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000013?line=0'>1</a>\u001b[0m losses, weights \u001b[39m=\u001b[39m crossValidate(y, x, \u001b[39m6\u001b[39;49m, \u001b[39m0.1\u001b[39;49m, \u001b[39m10000\u001b[39;49m, \u001b[39m0.01\u001b[39;49m, \u001b[39m0.5\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\RAZORBLADE\\Desktop\\Sem-VI\\CS331 - ML\\Machine-Learning-Tasks\\Machine-Learning-Tasks\\Assignment-03\\04-Regularisation\\02-Regularisation.ipynb Cell 11'\u001b[0m in \u001b[0;36mcrossValidate\u001b[1;34m(y, tx, k_fold, lambda_, max_iters, gamma, alpha)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000010?line=23'>24</a>\u001b[0m \u001b[39m#print(initial_w)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000010?line=24'>25</a>\u001b[0m \u001b[39m# train model and predict\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000010?line=25'>26</a>\u001b[0m losses_lasso, ws_lasso \u001b[39m=\u001b[39m LassoGD(y_train, tx_train,initial_w, lambda_, max_iters, gamma)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000010?line=26'>27</a>\u001b[0m losses_ridge, ws_ridge \u001b[39m=\u001b[39m RidgeGD(y_train, tx_train,initial_w, lambda_, max_iters, gamma)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000010?line=27'>28</a>\u001b[0m losses_elastic, ws_elastic \u001b[39m=\u001b[39m ElasticNetGD(y_train, tx_train, initial_w,lambda_, max_iters, gamma, alpha)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000010?line=28'>29</a>\u001b[0m \u001b[39m# append losses\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\RAZORBLADE\\Desktop\\Sem-VI\\CS331 - ML\\Machine-Learning-Tasks\\Machine-Learning-Tasks\\Assignment-03\\04-Regularisation\\02-Regularisation.ipynb Cell 5'\u001b[0m in \u001b[0;36mRidgeGD\u001b[1;34m(y, tx, initial_w, lambda_, max_iters, gamma)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000004?line=5'>6</a>\u001b[0m w \u001b[39m=\u001b[39m initial_w\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000004?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m n_iter \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iters):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000004?line=7'>8</a>\u001b[0m     \u001b[39m# compute gradient and loss\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000004?line=8'>9</a>\u001b[0m     grad \u001b[39m=\u001b[39m compute_gradient_Ridge(y, tx, w, lambda_)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000004?line=9'>10</a>\u001b[0m     loss \u001b[39m=\u001b[39m compute_loss_Ridge(y, tx, w, lambda_)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000004?line=10'>11</a>\u001b[0m     \u001b[39m# gradient w by descent update\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\RAZORBLADE\\Desktop\\Sem-VI\\CS331 - ML\\Machine-Learning-Tasks\\Machine-Learning-Tasks\\Assignment-03\\04-Regularisation\\02-Regularisation.ipynb Cell 6'\u001b[0m in \u001b[0;36mcompute_gradient_Ridge\u001b[1;34m(y, tx, w, lambda_)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000005?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_gradient_Ridge\u001b[39m(y, tx, w, lambda_):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000005?line=1'>2</a>\u001b[0m     \u001b[39m\"\"\"Compute the gradient.\"\"\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000005?line=2'>3</a>\u001b[0m     e \u001b[39m=\u001b[39m y \u001b[39m-\u001b[39m tx\u001b[39m.\u001b[39;49mdot(w)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000005?line=3'>4</a>\u001b[0m     grad \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mtx\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mdot(e) \u001b[39m+\u001b[39m lambda_ \u001b[39m*\u001b[39m w\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RAZORBLADE/Desktop/Sem-VI/CS331%20-%20ML/Machine-Learning-Tasks/Machine-Learning-Tasks/Assignment-03/04-Regularisation/02-Regularisation.ipynb#ch0000005?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m grad, e\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (10,) and (2,10) not aligned: 10 (dim 0) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "losses, weights = crossValidate(y, x, 6, 0.1, 10000, 0.01, 0.5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f23730d148f0a90638581163a05f33fe279101ed952ab2055512a2b448ea1fdc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
